{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCuYjs0kW_yl"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim, autograd\n",
    "import pdb\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import chain, combinations\n",
    "from scipy.stats import f as fdist\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from torch.autograd import grad\n",
    "\n",
    "import scipy.optimize\n",
    "\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrPIlQ12XDMJ"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Invariant regression')\n",
    "parser.add_argument('--dim', type=int, default=10)\n",
    "parser.add_argument('--n_samples', type=int, default=1000)\n",
    "parser.add_argument('--n_reps', type=int, default=3)\n",
    "parser.add_argument('--skip_reps', type=int, default=0)\n",
    "parser.add_argument('--seed', type=int, default=0)  # Negative is random\n",
    "parser.add_argument('--print_vectors', type=int, default=0)\n",
    "parser.add_argument('--n_iterations', type=int, default=10000)\n",
    "parser.add_argument('--lr', type=float, default=1e-3)\n",
    "parser.add_argument('--verbose', type=int, default=1)\n",
    "parser.add_argument('--methods', type=str, default=\"IRM,REIIL,IRM,EIIL\")\n",
    "parser.add_argument('--alpha', type=float, default=0.05)\n",
    "parser.add_argument('--setup_sem', type=str, default=\"chain\")\n",
    "parser.add_argument('--setup_hidden', type=int, default=0)\n",
    "parser.add_argument('--setup_hetero', type=int, default=2)\n",
    "parser.add_argument('--setup_scramble', type=int, default=0)\n",
    "parser.add_argument('--results_dir', type=str, default=\"./tmp/experiment_synthetic\")\n",
    "parser.add_argument('--eiil_ref_alpha', type=float, default=-1,\n",
    "                    help=('Value between zero and one to hard code the reference '\n",
    "                          'classifier propensity to use the spurious feature. Set '\n",
    "                          'to value outside zero one interval to disable.'))\n",
    "parser.add_argument('--reiil_iters', type=int, default=10)\n",
    "flags = dict(vars(parser.parse_args(['--n_rep', '3'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nwCHxwKXFF6",
    "outputId": "e12b88e9-8c97-4565-fd79-2efd8ae5ed80"
   },
   "outputs": [],
   "source": [
    "print('Flags:')\n",
    "for k,v in sorted(flags.items()):\n",
    "  print(\"\\t{}: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmb1V50tnKeN"
   },
   "outputs": [],
   "source": [
    "class ChainEquationModel(object):\n",
    "    def __init__(self, dim, scramble=False, hetero=True, hidden=False):\n",
    "        self.hetero = hetero\n",
    "        self.hidden = hidden\n",
    "        self.dim = dim // 2\n",
    "        ones = True\n",
    "\n",
    "        if ones:\n",
    "            self.wxy = torch.eye(self.dim)\n",
    "            self.wyz = torch.eye(self.dim)\n",
    "        else:\n",
    "            self.wxy = torch.randn(self.dim, self.dim) / dim\n",
    "            self.wyz = torch.randn(self.dim, self.dim) / dim\n",
    "\n",
    "        if scramble:\n",
    "            self.scramble, _ = torch.qr(torch.randn(dim, dim))\n",
    "        else:\n",
    "            self.scramble = torch.eye(dim)\n",
    "\n",
    "        if hidden:\n",
    "            self.whx = torch.randn(self.dim, self.dim) / dim\n",
    "            self.why = torch.randn(self.dim, self.dim) / dim\n",
    "            self.whz = torch.randn(self.dim, self.dim) / dim\n",
    "        else:\n",
    "            self.whx = torch.eye(self.dim, self.dim)\n",
    "            self.why = torch.zeros(self.dim, self.dim)\n",
    "            self.whz = torch.zeros(self.dim, self.dim)\n",
    "\n",
    "    def solution(self):\n",
    "        w = torch.cat((self.wxy.sum(1), torch.zeros(self.dim))).view(-1, 1)\n",
    "        return self.scramble.t() @ w\n",
    "\n",
    "    def __call__(self, n, env, split=None):\n",
    "        h = torch.randn(n, self.dim) * env\n",
    "\n",
    "        if self.hetero == 2:\n",
    "            if split:\n",
    "              num = int(n * split)\n",
    "              x_low_noise = torch.randn(num, self.dim) * 5.\n",
    "              x_rest = torch.randn(n - num, self.dim) * 5.\n",
    "              x = torch.cat((x_low_noise, x_rest), 0)\n",
    "              y_low_noise = x_low_noise @ self.wxy + torch.randn(num, self.dim) * 0.1\n",
    "              y_rest = x_rest @ self.wxy + torch.randn(n - num, self.dim) * env\n",
    "              y = torch.cat((y_low_noise, y_rest), 0)\n",
    "            else:\n",
    "              x = torch.randn(n, self.dim) * 5.\n",
    "              y = x @ self.wxy + torch.randn(n, self.dim) * env\n",
    "            z = y @ self.wyz + torch.randn(n, self.dim)\n",
    "        elif self.hetero == 1:\n",
    "            x = h @ self.whx + torch.randn(n, self.dim) * env\n",
    "            y = x @ self.wxy + h @ self.why + torch.randn(n, self.dim) * env\n",
    "            z = y @ self.wyz + h @ self.whz + torch.randn(n, self.dim)\n",
    "        else:\n",
    "            x = h @ self.whx + torch.randn(n, self.dim) * env\n",
    "            y = x @ self.wxy + h @ self.why + torch.randn(n, self.dim)\n",
    "            z = y @ self.wyz + h @ self.whz + torch.randn(n, self.dim) * env\n",
    "        variances = dict(\n",
    "          h=h.var().item(),\n",
    "          x=x.var().item(),\n",
    "          y=y.var().item(),\n",
    "          z=z.var().item(),\n",
    "          e=(torch.randn(n, self.dim) * env).var().item()  # any env dependent noise we might add\n",
    "        )\n",
    "        from pprint import pprint\n",
    "        print('in setting %d data in env %d have following variances' % (self.hetero, env))\n",
    "        pprint(variances)\n",
    "        return torch.cat((x, z), 1) @ self.scramble, y.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP2WZVlckMN-"
   },
   "outputs": [],
   "source": [
    "def pretty(vector):\n",
    "    vlist = vector.view(-1).tolist()\n",
    "    return \"[\" + \", \".join(\"{:+.4f}\".format(vi) for vi in vlist) + \"]\"\n",
    "\n",
    "#Models\n",
    "class InvariantRiskMinimization(object):\n",
    "    def __init__(self, environments, args):\n",
    "        best_reg = 0\n",
    "        best_err = 1e6\n",
    "\n",
    "        x_val = environments[2][0]\n",
    "        y_val = environments[2][1]\n",
    "\n",
    "        for reg in [0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "            reg = 1. - reg  # change of variables for consistency with old codebase\n",
    "            self.train(environments[:2], args, reg=reg)\n",
    "            err = (x_val @ self.solution() - y_val).pow(2).mean().item()\n",
    "\n",
    "            if args[\"verbose\"]:\n",
    "                print(\"IRM (reg={:.6f}) has {:.3f} validation error.\".format(\n",
    "                    reg, err))\n",
    "\n",
    "            if err < best_err:\n",
    "                best_err = err\n",
    "                best_reg = reg\n",
    "                best_phi = self.phi.clone()\n",
    "        self.phi = best_phi\n",
    "        print ('IRM best err and phi:', best_err, self.phi)\n",
    "        test_err = (environments[3][0] @ self.solution() - environments[3][1]).pow(2).mean().item()\n",
    "        print ('IRM test err [env=0]:', test_err)\n",
    "        test_err = (environments[4][0] @ self.solution() - environments[4][1]).pow(2).mean().item()\n",
    "        print ('IRM test err [env=5]:', test_err)\n",
    "        test_err = (environments[5][0] @ self.solution() - environments[5][1]).pow(2).mean().item()\n",
    "        print ('IRM test err [env=10]:', test_err)\n",
    "\n",
    "    def train(self, environments, args, reg=0):\n",
    "        print('learning representation with', self, 'and reg', reg)\n",
    "        dim_x = environments[0][0].size(1)\n",
    "\n",
    "        x_1 = torch.cat((environments[0][0][:100], environments[1][0][:200]), 0)\n",
    "        y_1 = torch.cat((environments[0][1][:100], environments[1][1][:200]), 0)\n",
    "        x_2 = torch.cat((environments[0][0][100:], environments[1][0][200:]), 0)\n",
    "        y_2 = torch.cat((environments[0][1][100:], environments[1][1][200:]), 0)\n",
    "\n",
    "        environments = [(x_1, y_1), (x_2, y_2)]\n",
    "\n",
    "        self.phi = torch.nn.Parameter(torch.eye(dim_x, dim_x))\n",
    "        self.w = torch.ones(dim_x, 1)\n",
    "        self.w.requires_grad = True\n",
    "\n",
    "        opt = torch.optim.Adam([self.phi], lr=args[\"lr\"])\n",
    "        loss = torch.nn.MSELoss()\n",
    "\n",
    "        for iteration in range(args[\"n_iterations\"]):\n",
    "            penalty = 0\n",
    "            error = 0\n",
    "            for x_e, y_e in environments:\n",
    "                error_e = loss(x_e @ self.phi @ self.w, y_e)\n",
    "                penalty += grad(error_e, self.w,\n",
    "                                create_graph=True)[0].pow(2).mean()\n",
    "                error += error_e\n",
    "\n",
    "            opt.zero_grad()\n",
    "#             (reg * error + (1 - reg) * penalty).backward()  # dumb; zero reg means regularize 100%\n",
    "            ((1 - reg) * error + reg * penalty).backward()  # good\n",
    "            opt.step()\n",
    "\n",
    "            if args[\"verbose\"] and iteration % 1000 == 0:\n",
    "                w_str = pretty(self.solution())\n",
    "                print(\"{:05d} | {:.5f} | {:.5f} | {:.5f} | {}\".format(iteration,\n",
    "                                                                      reg,\n",
    "                                                                      error,\n",
    "                                                                      penalty,\n",
    "                                                                      w_str))\n",
    "\n",
    "    def solution(self):\n",
    "        return self.phi @ self.w\n",
    "\n",
    "      \n",
    "class LearnedEnvInvariantRiskMinimization(InvariantRiskMinimization):\n",
    "    def __init__(self, environments, args, pretrain=False):\n",
    "        best_reg = 0\n",
    "        best_err = 1e6\n",
    "\n",
    "        x_val = environments[2][0]\n",
    "        y_val = environments[2][1]\n",
    "\n",
    "        if args['eiil_ref_alpha'] >= 0 and args['eiil_ref_alpha'] <= 1: \n",
    "            print('Using hard-coded reference classifier with alpha={:.2f}'.format(\n",
    "              args['eiil_ref_alpha']\n",
    "            ))\n",
    "            alpha = args['eiil_ref_alpha']\n",
    "            w_causal = (1. - alpha) * np.ones((1, 5))\n",
    "            w_noncausal = alpha * np.ones((1, 5))  # spurious contribution to prediction\n",
    "            w_ref = np.hstack((w_causal, w_noncausal))\n",
    "            w_ref = torch.tensor(w_ref, dtype=torch.float32)\n",
    "        else:\n",
    "            print('Using ERM soln as reference classifier.')\n",
    "            # w_ref = EmpiricalRiskMinimizer(environments[:-1], args).solution()\n",
    "            w_ref = EmpiricalRiskMinimizer(environments, args).solution()\n",
    "\n",
    "        self.phi = torch.nn.Parameter(torch.diag(w_ref.squeeze()))\n",
    "        dim_x = environments[0][0].size(1)\n",
    "        self.w = torch.ones(dim_x, 1)\n",
    "        self.w.requires_grad = True\n",
    "        err = (x_val @ self.solution() - y_val).pow(2).mean().item()\n",
    "\n",
    "        if args[\"verbose\"]:\n",
    "            print(\"EIIL's reference classifier has {:.3f} validation error.\".format(\n",
    "                err))\n",
    "            print(\"EIIL's reference classifier has the following solution:\\n.\",\n",
    "                  pretty(self.solution()))\n",
    "\n",
    "        self.phi = self.phi.clone()\n",
    "\n",
    "        environments, env_w = self.split(environments, args)\n",
    "        if args[\"verbose\"]:\n",
    "            print(\"EIIL+ERM ref clf still has the following solution after AED (sanity check):\\n.\", pretty(self.solution()))\n",
    "        best_reg = 0\n",
    "        best_err = 1e6\n",
    "\n",
    "        # Finding num flipped in minority.\n",
    "        idx = [(env_w.sigmoid()>.5), (env_w.sigmoid()<=.5)]\n",
    "        maj = 0\n",
    "        if torch.count_nonzero(idx[1]) > torch.count_nonzero(idx[0]):\n",
    "          maj = 1\n",
    "\n",
    "        total_flipped = 100 + 200\n",
    "        total_flipped_min = torch.count_nonzero(idx[1 - maj][:100]) + torch.count_nonzero(idx[1 - maj][1000:1200])\n",
    "        print (f'EIIL Total flipped in minority environment: {total_flipped_min} / {total_flipped} ({total_flipped_min / total_flipped * 100} %)')\n",
    "\n",
    "\n",
    "        for reg in [0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "            reg = 1. - reg  # change of variables for consistency with old codebase\n",
    "            # self.train(environments[:-1], args, reg=reg)\n",
    "            self.train(environments[:2], args, reg=reg)\n",
    "            err = (x_val @ self.solution() - y_val).pow(2).mean().item()\n",
    "\n",
    "            if args[\"verbose\"]:\n",
    "                print(\"EIIL+IRM (reg={:.6f}) has {:.3f} validation error.\".format(\n",
    "                    reg, err))\n",
    "\n",
    "            if err < best_err:\n",
    "                best_err = err\n",
    "                best_reg = reg\n",
    "                best_phi = self.phi.clone()\n",
    "        self.phi = best_phi\n",
    "        print ('EIIL best err and phi:', best_err, self.phi)\n",
    "        test_err = (environments[3][0] @ self.solution() - environments[3][1]).pow(2).mean().item()\n",
    "        print ('EIIL test err [env=0]:', test_err)\n",
    "        test_err = (environments[4][0] @ self.solution() - environments[4][1]).pow(2).mean().item()\n",
    "        print ('EIIL test err [env=5]:', test_err)\n",
    "        test_err = (environments[5][0] @ self.solution() - environments[5][1]).pow(2).mean().item()\n",
    "        print ('EIIL test err [env=10]:', test_err)\n",
    "\n",
    "\n",
    "    def split(self, environments, args, n_samples=-1):\n",
    "          \"\"\"Learn soft environment assignment.\"\"\"\n",
    "          envs = environments\n",
    "          # test_env = envs[-1]\n",
    "          test_envs = envs[2:]\n",
    "          x = torch.cat((envs[0][0][:n_samples],envs[1][0][:n_samples]),0)\n",
    "          y = torch.cat((envs[0][1][:n_samples],envs[1][1][:n_samples]),0)\n",
    "          print('size of pooled envs: '+str(len(x)))\n",
    "     \n",
    "          loss = torch.nn.MSELoss(reduction='none')\n",
    "          error = loss(x @ self.phi @ self.w, y)\n",
    "\n",
    "          env_w = torch.randn(len(error)).requires_grad_()\n",
    "          optimizer = torch.optim.Adam([env_w], lr=0.001)\n",
    "\n",
    "          print('learning soft environment assignments')\n",
    "          prev_penalty = 0\n",
    "          ind = 0\n",
    "          max_diff = -np.inf\n",
    "          pbar = tqdm(range(args['n_iterations']))\n",
    "          for i in pbar:\n",
    "            # penalty for env a\n",
    "            error_a = (error.squeeze() * env_w.sigmoid()).mean()\n",
    "            penalty_a = grad(error_a, self.w, create_graph=True)[0].pow(2).mean()\n",
    "            # penalty for env b\n",
    "            error_b = (error.squeeze() * (1-env_w.sigmoid())).mean()\n",
    "            penalty_b = grad(error_b, self.w, create_graph=True)[0].pow(2).mean()\n",
    "            # negate\n",
    "            npenalty = - torch.stack([penalty_a, penalty_b]).mean()\n",
    "            if i > 0:\n",
    "              diff = abs(npenalty.item() - prev_penalty)\n",
    "            else:\n",
    "              diff = -np.inf\n",
    "            if diff > max_diff:\n",
    "              max_diff = diff\n",
    "              ind = i\n",
    "            pbar.set_description_str(desc='Negative Penalty: '+str(npenalty.item())+', Diff: '+str(diff)+', Max Diff: '+str(max_diff)+'('+str(ind)+')')\n",
    "            prev_penalty = npenalty.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            npenalty.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "          idx0 = (env_w.sigmoid()>.5)\n",
    "          idx1 = (env_w.sigmoid()<=.5)\n",
    "          \n",
    "          envs = []\n",
    "          envs.append((x[idx0],y[idx0]))\n",
    "          print('size of env 0: '+str(len(x[idx0])))\n",
    "          envs.append((x[idx1],y[idx1]))\n",
    "          print('size of env 1: '+str(len(x[idx1])))\n",
    "          print('weights: '+str(env_w.sigmoid()))\n",
    "          # envs.append(test_env)\n",
    "          envs.extend(test_envs)\n",
    "          return envs, env_w\n",
    "\n",
    "class RepeatedEIIL(InvariantRiskMinimization):\n",
    "    def __init__(self, environments, args, pretrain=False):\n",
    "        best_reg = 0\n",
    "        best_err = 1e6\n",
    "\n",
    "        # x_val = environments[-1][0]\n",
    "        x_val = environments[2][0]\n",
    "        # y_val = environments[-1][1]\n",
    "        y_val = environments[2][1]\n",
    "        self.reiters = args['reiil_iters']\n",
    "\n",
    "        min_env = []\n",
    "        new_envs = environments.copy()\n",
    "        best_reg = 0\n",
    "        best_err = 1e6\n",
    "\n",
    "        for i in range(self.reiters):\n",
    "\n",
    "          if args['eiil_ref_alpha'] >= 0 and args['eiil_ref_alpha'] <= 1: \n",
    "              print('Using hard-coded reference classifier with alpha={:.2f}'.format(\n",
    "                args['eiil_ref_alpha']\n",
    "              ))\n",
    "              alpha = args['eiil_ref_alpha']\n",
    "              w_causal = (1. - alpha) * np.ones((1, 5))\n",
    "              w_noncausal = alpha * np.ones((1, 5))  # spurious contribution to prediction\n",
    "              w_ref = np.hstack((w_causal, w_noncausal))\n",
    "              w_ref = torch.tensor(w_ref, dtype=torch.float32)\n",
    "          else:\n",
    "              print(str(i)+': Using ERM soln as reference classifier.')\n",
    "              # w_ref = EmpiricalRiskMinimizer(new_envs[:-1], args).solution()\n",
    "              w_ref = EmpiricalRiskMinimizer(new_envs, args).solution()\n",
    "\n",
    "          self.phi = torch.nn.Parameter(torch.diag(w_ref.squeeze()))\n",
    "          dim_x = new_envs[0][0].size(1)\n",
    "          self.w = torch.ones(dim_x, 1)\n",
    "          self.w.requires_grad = True\n",
    "          err = (x_val @ self.solution() - y_val).pow(2).mean().item()\n",
    "\n",
    "          self.phi = self.phi.clone()\n",
    "\n",
    "          if args[\"verbose\"]:\n",
    "              print(str(i)+\": REIIL's reference classifier has {:.3f} validation error.\".format(\n",
    "                  err))\n",
    "              print(str(i)+\": REIIL's reference classifier has the following solution:\\n.\",\n",
    "                    pretty(self.solution()))\n",
    "\n",
    "          new_envs, env_w = self.split(environments, args)\n",
    "\n",
    "          # Finding num flipped in minority.\n",
    "          idx = [(env_w.sigmoid()>.5), (env_w.sigmoid()<=.5)]\n",
    "          maj = 0\n",
    "          if torch.count_nonzero(idx[1]) > torch.count_nonzero(idx[0]):\n",
    "            maj = 1\n",
    "\n",
    "          total_flipped = 100 + 200\n",
    "          total_flipped_min = torch.count_nonzero(idx[1 - maj][:100]) + torch.count_nonzero(idx[1 - maj][1000:1200])\n",
    "          print (f'REIIL {i} Total flipped in minority environment: {total_flipped_min} / {total_flipped} ({total_flipped_min / total_flipped * 100} %)')\n",
    "\n",
    "          rest_envs = new_envs.copy()\n",
    "          if args[\"verbose\"]:\n",
    "              print(\"REIIL+ERM ref clf still has the following solution after AED (sanity check):\\n.\", pretty(self.solution()))\n",
    "\n",
    "          if i < self.reiters - 1:\n",
    "            maj_ind = 0\n",
    "            if len(new_envs[1][0]) > len(new_envs[0][0]):\n",
    "              maj_ind = 1\n",
    "\n",
    "            min_env = new_envs[1 - maj_ind]\n",
    "            # new_envs = [new_envs[maj_ind], new_envs[2]]\n",
    "            new_envs = [new_envs[maj_ind], new_envs[2], new_envs[3], new_envs[4], new_envs[5]]\n",
    "\n",
    "          for reg in [0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "\n",
    "              reg = 1. - reg  # change of variables for consistency with old codebase\n",
    "              # self.train(rest_envs[:-1], args, reg=reg)\n",
    "              self.train(rest_envs[:2], args, reg=reg)\n",
    "              err = (x_val @ self.solution() - y_val).pow(2).mean().item()\n",
    "\n",
    "              if args[\"verbose\"]:\n",
    "                  print(str(i)+\": REIIL+IRM (reg={:.6f}) has {:.3f} validation error.\".format(\n",
    "                      reg, err))\n",
    "\n",
    "              if err < best_err:\n",
    "                  best_err = err\n",
    "                  best_reg = reg\n",
    "                  best_phi = self.phi.clone()\n",
    "          self.phi = best_phi\n",
    "          print ('REIIL best err and phi:', best_err, self.phi)\n",
    "          test_err = (environments[3][0] @ self.solution() - environments[3][1]).pow(2).mean().item()\n",
    "          print ('REIIL test err [env=0]:', test_err)\n",
    "          test_err = (environments[4][0] @ self.solution() - environments[4][1]).pow(2).mean().item()\n",
    "          print ('REIIL test err [env=5]:', test_err)\n",
    "          test_err = (environments[5][0] @ self.solution() - environments[5][1]).pow(2).mean().item()\n",
    "          print ('REIIL test err [env=10]:', test_err)\n",
    "\n",
    "\n",
    "    def split(self, environments, args, n_samples=-1):\n",
    "          \"\"\"Learn soft environment assignment.\"\"\"\n",
    "          envs = environments\n",
    "          # test_env = envs[-1]\n",
    "          test_envs = envs[2:]\n",
    "          x = torch.cat((envs[0][0][:n_samples],envs[1][0][:n_samples]),0)\n",
    "          y = torch.cat((envs[0][1][:n_samples],envs[1][1][:n_samples]),0)\n",
    "          print('size of pooled envs: '+str(len(x)))\n",
    "     \n",
    "          loss = torch.nn.MSELoss(reduction='none')\n",
    "          error = loss(x @ self.phi @ self.w, y)\n",
    "\n",
    "          env_w = torch.randn(len(error)).requires_grad_()\n",
    "          optimizer = torch.optim.Adam([env_w], lr=0.001)\n",
    "\n",
    "          print('learning soft environment assignments')\n",
    "          prev_penalty = 0\n",
    "          ind = 0\n",
    "          max_diff = -np.inf\n",
    "          pbar = tqdm(range(args['n_iterations']))\n",
    "          for i in pbar:\n",
    "            # penalty for env a\n",
    "            error_a = (error.squeeze() * env_w.sigmoid()).mean()\n",
    "            penalty_a = grad(error_a, self.w, create_graph=True)[0].pow(2).mean()\n",
    "            # penalty for env b\n",
    "            error_b = (error.squeeze() * (1-env_w.sigmoid())).mean()\n",
    "            penalty_b = grad(error_b, self.w, create_graph=True)[0].pow(2).mean()\n",
    "            # negate\n",
    "            npenalty = - torch.stack([penalty_a, penalty_b]).mean()\n",
    "            if i > 0:\n",
    "              diff = abs(npenalty.item() - prev_penalty)\n",
    "            else:\n",
    "              diff = -np.inf\n",
    "            if diff > max_diff:\n",
    "              max_diff = diff\n",
    "              ind = i\n",
    "            pbar.set_description_str(desc='Negative Penalty: '+str(npenalty.item())+', Diff: '+str(diff)+', Max Diff: '+str(max_diff)+'('+str(ind)+')')\n",
    "            prev_penalty = npenalty.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            npenalty.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "          envs = []\n",
    "          idx0 = (env_w.sigmoid()>.5)\n",
    "          idx1 = (env_w.sigmoid()<=.5)\n",
    "          envs.append((x[idx0],y[idx0]))\n",
    "          print('size of env 0: '+str(len(x[idx0])))\n",
    "          envs.append((x[idx1],y[idx1]))\n",
    "          print('size of env 1: '+str(len(x[idx1])))\n",
    "          print('weights: '+str(env_w.sigmoid()))\n",
    "          # envs.append(test_env)\n",
    "          envs.extend(test_envs)\n",
    "          return envs, env_w\n",
    "\n",
    " \n",
    "class InvariantCausalPrediction(object):\n",
    "    def __init__(self, environments, args):\n",
    "        self.coefficients = None\n",
    "        self.alpha = args[\"alpha\"]\n",
    "\n",
    "        x_all = []\n",
    "        y_all = []\n",
    "        e_all = []\n",
    "\n",
    "        for e, (x, y) in enumerate(environments):\n",
    "            x_all.append(x.numpy())\n",
    "            y_all.append(y.numpy())\n",
    "            e_all.append(np.full(x.shape[0], e))\n",
    "\n",
    "        x_all = np.vstack(x_all)\n",
    "        y_all = np.vstack(y_all)\n",
    "        e_all = np.hstack(e_all)\n",
    "\n",
    "        dim = x_all.shape[1]\n",
    "\n",
    "        accepted_subsets = []\n",
    "        for subset in self.powerset(range(dim)):\n",
    "            if len(subset) == 0:\n",
    "                continue\n",
    "\n",
    "            x_s = x_all[:, subset]\n",
    "            reg = LinearRegression(fit_intercept=False).fit(x_s, y_all)\n",
    "\n",
    "            p_values = []\n",
    "            for e in range(len(environments)):\n",
    "                e_in = np.where(e_all == e)[0]\n",
    "                e_out = np.where(e_all != e)[0]\n",
    "\n",
    "                res_in = (y_all[e_in] - reg.predict(x_s[e_in, :])).ravel()\n",
    "                res_out = (y_all[e_out] - reg.predict(x_s[e_out, :])).ravel()\n",
    "\n",
    "                p_values.append(self.mean_var_test(res_in, res_out))\n",
    "\n",
    "            # TODO: Jonas uses \"min(p_values) * len(environments) - 1\"\n",
    "            p_value = min(p_values) * len(environments)\n",
    "\n",
    "            if p_value > self.alpha:\n",
    "                accepted_subsets.append(set(subset))\n",
    "                if args[\"verbose\"]:\n",
    "                    print(\"Accepted subset:\", subset)\n",
    "\n",
    "        if len(accepted_subsets):\n",
    "            accepted_features = list(set.intersection(*accepted_subsets))\n",
    "            if args[\"verbose\"]:\n",
    "                print(\"Intersection:\", accepted_features)\n",
    "            self.coefficients = np.zeros(dim)\n",
    "\n",
    "            if len(accepted_features):\n",
    "                x_s = x_all[:, list(accepted_features)]\n",
    "                reg = LinearRegression(fit_intercept=False).fit(x_s, y_all)\n",
    "                self.coefficients[list(accepted_features)] = reg.coef_\n",
    "\n",
    "            self.coefficients = torch.Tensor(self.coefficients)\n",
    "        else:\n",
    "            self.coefficients = torch.zeros(dim)\n",
    "\n",
    "    def mean_var_test(self, x, y):\n",
    "        pvalue_mean = ttest_ind(x, y, equal_var=False).pvalue\n",
    "        pvalue_var1 = 1 - fdist.cdf(np.var(x, ddof=1) / np.var(y, ddof=1),\n",
    "                                    x.shape[0] - 1,\n",
    "                                    y.shape[0] - 1)\n",
    "\n",
    "        pvalue_var2 = 2 * min(pvalue_var1, 1 - pvalue_var1)\n",
    "\n",
    "        return 2 * min(pvalue_mean, pvalue_var2)\n",
    "\n",
    "    def powerset(self, s):\n",
    "        return chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))\n",
    "\n",
    "    def solution(self):\n",
    "        return self.coefficients\n",
    "\n",
    "\n",
    "class EmpiricalRiskMinimizer(object):\n",
    "    def __init__(self, environments, args):\n",
    "        # x_all = torch.cat([x for (x, y) in environments[:-1]]).numpy()\n",
    "        print ('ERM training environments: ', len(environments[:-4]))\n",
    "        x_all = torch.cat([x for (x, y) in environments[:-4]]).numpy()\n",
    "        # y_all = torch.cat([y for (x, y) in environments[:-1]]).numpy()\n",
    "        y_all = torch.cat([y for (x, y) in environments[:-4]]).numpy()\n",
    "\n",
    "        x_val = environments[-4][0].numpy()\n",
    "        y_val = environments[-4][1].numpy()\n",
    "        x_test = environments[-1][0].numpy()\n",
    "        y_test = environments[-1][1].numpy()\n",
    "\n",
    "        w = LinearRegression(fit_intercept=False).fit(x_all, y_all).coef_\n",
    "        self.w = torch.Tensor(w)\n",
    "        if args['verbose']:\n",
    "          print('Done training ERM.')\n",
    "          # print (x_all[:2], x_all.dot(self.solution().T)[:2], y_all[:2])\n",
    "          # input()\n",
    "          err = np.mean((x_all.dot(self.solution().T) - y_all) ** 2.).item()\n",
    "          print(\"ERM has {:.3f} train error.\".format(err))\n",
    "          err = np.mean((environments[-4][0].numpy().dot(self.solution().T) - environments[-4][1].numpy()) ** 2.).item()\n",
    "          print(\"ERM has {:.3f} val error.\".format(err))\n",
    "          err = np.mean((environments[-3][0].numpy().dot(self.solution().T) - environments[-3][1].numpy()) ** 2.).item()\n",
    "          print(\"ERM has {:.3f} test error [env=0].\".format(err))\n",
    "          err = np.mean((environments[-2][0].numpy().dot(self.solution().T) - environments[-2][1].numpy()) ** 2.).item()\n",
    "          print(\"ERM has {:.3f} test error [env=5].\".format(err))\n",
    "          err = np.mean((environments[-1][0].numpy().dot(self.solution().T) - environments[-1][1].numpy()) ** 2.).item()\n",
    "          print(\"ERM has {:.3f} test error [env=10].\".format(err))\n",
    "          print(\"ERM has the following solution:\\n \", pretty(self.solution()))\n",
    "\n",
    "    def solution(self):\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eicsPBUunQnT"
   },
   "outputs": [],
   "source": [
    "def pretty(vector):\n",
    "    vlist = vector.view(-1).tolist()\n",
    "    return \"[\" + \", \".join(\"{:+.3f}\".format(vi) for vi in vlist) + \"]\"\n",
    "\n",
    "\n",
    "def errors(w, w_hat):\n",
    "    w = w.view(-1)\n",
    "    w_hat = w_hat.view(-1)\n",
    "\n",
    "    i_causal = (w != 0).nonzero().view(-1)\n",
    "    i_noncausal = (w == 0).nonzero().view(-1)\n",
    "\n",
    "    if len(i_causal):\n",
    "        error_causal = (w[i_causal] - w_hat[i_causal]).pow(2).mean()\n",
    "        error_causal = error_causal.item()\n",
    "    else:\n",
    "        error_causal = 0\n",
    "\n",
    "    if len(i_noncausal):\n",
    "        error_noncausal = (w[i_noncausal] - w_hat[i_noncausal]).pow(2).mean()\n",
    "        error_noncausal = error_noncausal.item()\n",
    "    else:\n",
    "        error_noncausal = 0\n",
    "\n",
    "    return error_causal, error_noncausal\n",
    "\n",
    "\n",
    "def run_experiment(args):\n",
    "    if args[\"seed\"] >= 0:\n",
    "        torch.manual_seed(args[\"seed\"])\n",
    "        np.random.seed(args[\"seed\"])\n",
    "        torch.set_num_threads(1)\n",
    "\n",
    "    if args[\"setup_sem\"] == \"chain\":\n",
    "        setup_str = \"chain_hidden={}_hetero={}_scramble={}\".format(\n",
    "            args[\"setup_hidden\"],\n",
    "            args[\"setup_hetero\"],\n",
    "            args[\"setup_scramble\"])\n",
    "    elif args[\"setup_sem\"] == \"icp\":\n",
    "        setup_str = \"sem_icp\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    args['results_dir'] = os.path.join(args['results_dir'], setup_str)\n",
    "    if args['eiil_ref_alpha'] >= 0 and args['eiil_ref_alpha'] <= 1: \n",
    "        args['results_dir'] = '{results_dir}_alpha_{eiil_ref_alpha:.1f}'.format(**args)\n",
    " \n",
    "    if not os.path.exists(args['results_dir']):\n",
    "        os.makedirs(args['results_dir'])\n",
    "    pickle.dump(args, open(os.path.join(args['results_dir'], 'flags.p'), 'wb'))\n",
    "    for f in sys.stdout, open(os.path.join(args['results_dir'], 'flags.txt'), 'w'):\n",
    "        print('Flags:', file=f)\n",
    "        for k,v in sorted(args.items()):\n",
    "            print(\"\\t{}: {}\".format(k, v), file=f)\n",
    "    print('results will be found here:')\n",
    "    print(args['results_dir'])\n",
    "    \n",
    "    all_methods = {\n",
    "        \"ERM\": EmpiricalRiskMinimizer,\n",
    "        \"ICP\": InvariantCausalPrediction,\n",
    "        \"IRM\": InvariantRiskMinimization,\n",
    "        \"EIIL\": LearnedEnvInvariantRiskMinimization,\n",
    "        \"REIIL\": RepeatedEIIL\n",
    "    }\n",
    "\n",
    "    if args[\"methods\"] == \"all\":\n",
    "        methods = all_methods\n",
    "    else:\n",
    "        methods = {m: all_methods[m] for m in args[\"methods\"].split(',')}\n",
    "\n",
    "    all_sems = []\n",
    "    all_solutions = []\n",
    "    all_environments = []\n",
    "    from collections import defaultdict\n",
    "    all_err_causal = defaultdict(list)\n",
    "    all_err_noncausal = defaultdict(list)\n",
    "\n",
    "    for rep_i in range(args[\"n_reps\"]):\n",
    "        if args[\"setup_sem\"] == \"chain\":\n",
    "            sem = ChainEquationModel(args[\"dim\"],\n",
    "                                     hidden=args[\"setup_hidden\"],\n",
    "                                     scramble=args[\"setup_scramble\"],\n",
    "                                     hetero=args[\"setup_hetero\"])\n",
    "            # environments = [sem(args[\"n_samples\"], .2),\n",
    "            #                 sem(args[\"n_samples\"], 2.),\n",
    "            #                 sem(args[\"n_samples\"], 3.5),\n",
    "            #                 sem(args[\"n_samples\"], 0.),\n",
    "            #                 sem(args[\"n_samples\"], 5.),\n",
    "            #                 sem(args[\"n_samples\"], 10.)]\n",
    "            environments = [sem(args[\"n_samples\"], 3., 0.1),\n",
    "                            sem(args[\"n_samples\"], 3., 0.2),\n",
    "                            sem(args[\"n_samples\"], 3.5),\n",
    "                            sem(args[\"n_samples\"], 0.),\n",
    "                            sem(args[\"n_samples\"], 5.),\n",
    "                            sem(args[\"n_samples\"], 10.)]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        all_sems.append(sem)\n",
    "        all_environments.append(environments)\n",
    "      \n",
    "    for sem, environments in zip(all_sems, all_environments):\n",
    "        soln = sem.solution()\n",
    "        solutions = [\n",
    "            \"{} {:<5} {} {:.5f} {:.5f}\".format(setup_str,\n",
    "                                             \"SEM\",\n",
    "                                             pretty(sem.solution()), 0, 0)\n",
    "        ]\n",
    "        \n",
    "\n",
    "        for method_name, method_constructor in methods.items():\n",
    "            method = method_constructor(environments, args)\n",
    "            msolution = method.solution()\n",
    "            err_causal, err_noncausal = errors(sem.solution(), msolution)\n",
    "            all_err_causal[method_name].append(err_causal)\n",
    "            all_err_noncausal[method_name].append(err_noncausal)\n",
    "            solutions.append(\"{} {:<5} {} {:.5f} {:.5f}\".format(setup_str,\n",
    "                                                             method_name,\n",
    "                                                             pretty(msolution),\n",
    "                                                             err_causal,\n",
    "                                                             err_noncausal))\n",
    "\n",
    "        all_solutions += solutions\n",
    "\n",
    "    # save results\n",
    "    results = dict()\n",
    "    results.update(setup_str=setup_str)\n",
    "    results.update(all_sems=all_sems)\n",
    "    results.update(all_solutions=all_solutions)\n",
    "    results.update(all_environments=all_environments)\n",
    "    results.update(all_environments=all_environments)\n",
    "    results.update(all_err_causal=all_err_causal)\n",
    "    results.update(all_err_noncausal=all_err_noncausal)\n",
    "    with open(os.path.join(args['results_dir'], 'results.p'), 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    return all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QL0a5Qc6oP96",
    "outputId": "296f7a3b-4ccb-4a79-ae8f-f48349d7ee35"
   },
   "outputs": [],
   "source": [
    "hidden = [0]\n",
    "hetero = [1]\n",
    "scramble = [1]\n",
    "for i in range(1):\n",
    "  # flags['setup_hidden'] = hidden[i]\n",
    "  # flags['setup_hetero'] = hetero[i]\n",
    "  # flags['setup_scramble'] = scramble[i]\n",
    "\n",
    "  all_solutions = run_experiment(flags)\n",
    "  print(\"\\n\".join(all_solutions))\n",
    "  print(\"\\n\".join(all_solutions), file=open(\n",
    "    os.path.join(flags['results_dir'], 'all_solutions.txt'), 'w')\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "synth_git.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
